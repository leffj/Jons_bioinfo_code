map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
hist(map.bySite.use[,var],main=var)
#var.dm = vegdist(map.bySite.use[,var],method='euclidean',na.rm=T)
var.dm = vegdist(decostand(map.bySite.use[,var],method='standardize'),method='euclidean',na.rm=T)
mantel(var.dm,data.use.dm,method="spearman",na.rm=T,permutations=9999)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_unite75_wTax_485_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
hist(map.bySite.use[,var],main=var)
#var.dm = vegdist(map.bySite.use[,var],method='euclidean',na.rm=T)
var.dm = vegdist(decostand(map.bySite.use[,var],method='standardize'),method='euclidean',na.rm=T)
mantel(var.dm,data.use.dm,method="spearman",na.rm=T,permutations=9999)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
hist(map.bySite.use[,var],main=var)
#var.dm = vegdist(map.bySite.use[,var],method='euclidean',na.rm=T)
var.dm = vegdist(decostand(map.bySite.use[,var],method='standardize'),method='euclidean',na.rm=T)
mantel(var.dm,data.use.dm,method="spearman",na.rm=T,permutations=9999)
library(ecodist)
C2N.dm = egdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+sand.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_unite75_wTax_485_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
hist(map.bySite.use[,var],main=var)
#var.dm = vegdist(map.bySite.use[,var],method='euclidean',na.rm=T)
var.dm = vegdist(decostand(map.bySite.use[,var],method='standardize'),method='euclidean',na.rm=T)
mantel(var.dm,data.use.dm,method="spearman",na.rm=T,permutations=9999)
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+ppmP.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+C2N.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_k__Archaea_100_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
hist(map.bySite.use[,var],main=var)
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+pctN.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+pctN.dm+C2N.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_k__Bacteria_18000_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
names(map.bySite.use)
var = names(map.bySite.use)[16]
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
#plant
MRM(formula=data.use.dm~mat.dm+sand.dm,mrank=T)
MRM(formula=data.use.dm~livePlant.dm+map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+pctN.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+ppmP.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+sand.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm,mrank=T)
dataP_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
dataP = read.table(file=dataP_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# get map in same order as dm
samplesToUse = intersect(names(data.use),names(dataP))
dataP.use = dataP[match(samplesToUse,row.names(dataP)),match(samplesToUse,names(dataP))]
# make cmty dm
dataP.use.dm = as.dist(dataP.use)
# run MRM
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm+dataP.use.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+dataP.use.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+sand.dm+dataP.use.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_unite75_wTax_485_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
map_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/metadata_controls_updated_noNN10.csv'
map = read.csv(file=map_fp,header=T,row.names=1,check.names=F)
map.bySite = ddply(map,.(site_code,continent),summarize,lnlive_mass=log(mean(live_mass)+1),
lntotal_mass=log(mean(total_mass)+1),MAP=mean(MAP),MAT=mean(MAT),
MAP_VAR=mean(MAP_VAR),TEMP_VAR=mean(TEMP_VAR),lnsoil_pctN=log(mean(soil_pctN,na.rm=T)+1),
lnsoil_ppmP=log(mean(soil_ppmP,na.rm=T)+1),soil_pH=mean(soil_pH,na.rm=T),lnPlant_Rich=log(mean(rich,na.rm=T)+1),
PercentSand=mean(PercentSand,na.rm=T),cult=mean(Cult,na.rm=T),grazed=mean(RecentGz,na.rm=T),
lnCtoN=log(mean(C_to_N,na.rm=T)+1))
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
dataP_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
dataP = read.table(file=dataP_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# get map in same order as dm
samplesToUse = intersect(names(data.use),names(dataP))
dataP.use = dataP[match(samplesToUse,row.names(dataP)),match(samplesToUse,names(dataP))]
# make cmty dm
dataP.use.dm = as.dist(dataP.use)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+C2N.dm+dataP.use.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_k__Bacteria_18000_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
# make the environ dm
dataP_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
dataP = read.table(file=dataP_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# get map in same order as dm
samplesToUse = intersect(names(data.use),names(dataP))
dataP.use = dataP[match(samplesToUse,row.names(dataP)),match(samplesToUse,names(dataP))]
# make cmty dm
dataP.use.dm = as.dist(dataP.use)
# run MRM
#bact
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+sand.dm+dataP.use.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm+dataP.use.dm,mrank=T)
MRM(formula=data.use.dm~map.dm+mat.dm+soil_ph.dm+C2N.dm,mrank=T)
data_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/beta_div/sqrt_bray_curtis_otu_table_k__Archaea_100_controls_avgSiteCode.txt'
data = read.table(file=data_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# remove sites with na for pH
map.bySite = map.bySite[!is.na(map.bySite$soil_pH),]
# get map in same order as dm
samplesToUse = intersect(map.bySite$site_code,row.names(data))
data.use = data[match(samplesToUse,row.names(data)),match(samplesToUse,names(data))]
map.bySite.use = map.bySite[match(samplesToUse,map.bySite$site_code),]
# make cmty dm
data.use.dm = as.dist(data.use)
MRM(formula=data.use.dm~mat.dm+sand.dm,mrank=T)
dataP_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
dataP = read.table(file=dataP_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# get map in same order as dm
samplesToUse = intersect(names(data.use),names(dataP))
dataP.use = dataP[match(samplesToUse,row.names(dataP)),match(samplesToUse,names(dataP))]
# make cmty dm
dataP.use.dm = as.dist(dataP.use)
# run MRM
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+pctN.dm+C2N.dm,mrank=T)
livePlant.dm = vegdist(decostand(map.bySite.use$lnlive_mass,method='standardize'),method='euclidean',na.rm=T)
map.dm = vegdist(decostand(map.bySite.use$MAP,method='standardize'),method='euclidean',na.rm=T)
mat.dm = vegdist(decostand(map.bySite.use$MAT,method='standardize'),method='euclidean',na.rm=T)
soil_ph.dm = vegdist(decostand(map.bySite.use$soil_pH,method='standardize',na.rm=T),method='euclidean',na.rm=T)
pctN.dm = vegdist(decostand(map.bySite.use$lnsoil_pctN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
ppmP.dm = vegdist(decostand(map.bySite.use$lnsoil_ppmP,method='standardize',na.rm=T),method='euclidean',na.rm=T)
sand.dm = vegdist(decostand(map.bySite.use$PercentSand,method='standardize',na.rm=T),method='euclidean',na.rm=T)
C2N.dm = vegdist(decostand(map.bySite.use$lnCtoN,method='standardize',na.rm=T),method='euclidean',na.rm=T)
dataP_fp = '/Users/leffj/Dropbox/NutNet/NutNet_microbe_diversity/veg_data/hellinger_bray_curtis_max_cover_genus_matrix_controls_avg_by_site_code.txt'
dataP = read.table(file=dataP_fp,header=T,sep='\t',row.names=1,check.names=F,comment.char='')
# get map in same order as dm
samplesToUse = intersect(names(data.use),names(dataP))
dataP.use = dataP[match(samplesToUse,row.names(dataP)),match(samplesToUse,names(dataP))]
# make cmty dm
dataP.use.dm = as.dist(dataP.use)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+pctN.dm+C2N.dm,mrank=T)
MRM(formula=data.use.dm~mat.dm+soil_ph.dm+pctN.dm+C2N.dm+dataP.use.dm,mrank=T)
library(vegan)
dmat.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/data.csv'
dmat = read.csv(dmat.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
dmat = read.csv(dmat.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
View(dmat)
data.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/data.csv'
data = read.csv(dmat.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
dmat = vegdist(t(data), method="bray")
data.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/data.csv'
data = read.csv(dmat.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
View(data)
dmat = vegdist(t(data), method="bray")
map.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/key.csv'
cat = "regionSite"
out.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/ARISA_dissim_avgByRegionSite.txt'
map = read.table(map.f,header=TRUE,row.names=1,sep='\t',check.names=FALSE,comment.char="")
dmat.clmns = data.frame(t(combn(unlist(labels(dmat)[1]),2)),as.numeric(as.dist(dmat)))
names(dmat.clmns) = c('x1','x2','dist')
# list x1 and x2 categories in new clmns
cat1 = map[match(dmat.clmns$x1,row.names(map)),cat]
cat2 = map[match(dmat.clmns$x2,row.names(map)),cat]
dmat.clmns = cbind(dmat.clmns,cat1,cat2)
# only take samples in mapping file
dmat.clmns = dmat.clmns[!is.na(dmat.clmns$cat1) & !is.na(dmat.clmns$cat2),]
# retain rows where distances are comparing samples from the same cat
dmat.clmns.reduced = dmat.clmns[dmat.clmns$cat1 != dmat.clmns$cat2,]
# combine cat columns to form comparison categories
# however, need to realize 'cat1__cat2' is equal to 'cat2__cat1'
# make df with every unique combination of cat levels
uniqueLevels = levels(factor(c(as.character(dmat.clmns.reduced$cat1),as.character(dmat.clmns.reduced$cat2))))
categories = data.frame(t(combn(uniqueLevels,2)))
# make a vector with each combination (first,second and second,first) for each combination
categorieslookup = paste(categories[,1],categories[,2])
categorieslookup = c(categorieslookup,paste(categories[,2],categories[,1]))
# make a vector with an index number for each combination of cat levels that associates with lookup vec
catIndex = c(seq.int(1,nrow(categories)),seq.int(1,nrow(categories)))
# now match the category combination (cat1 + cat2) in the dataset to the combination in
#    the lookup vec and pull the category index
joinedCats = paste(dmat.clmns.reduced$cat1,dmat.clmns.reduced$cat2)
distCats = catIndex[match(joinedCats,categorieslookup)]
dmat.clmns.reduced = cbind(dmat.clmns.reduced,distCats)
# get measure of center for each distance category
byCatDists = tapply(dmat.clmns.reduced$dist,INDEX=dmat.clmns.reduced$distCats,FUN=fun)
byCatDists.clms = cbind(as.character(categories[,1]),as.character(categories[,2]),as.vector(byCatDists))
row.names(byCatDists.clms) = NULL
# convert 3 column distances back to matrix format
uNames = as.character(uniqueLevels)
byCatDists.dmat = data.frame(matrix(ncol=length(uNames),nrow=length(uNames)))
names(byCatDists.dmat) = uNames
row.names(byCatDists.dmat) = uNames
for(i in 1:nrow(byCatDists.clms)){
byCatDists.dmat[byCatDists.clms[i,1],byCatDists.clms[i,2]] = as.character(byCatDists.clms[i,3])
}
for(i in 1:nrow(byCatDists.dmat)){
for(k in 1:ncol(byCatDists.dmat)){
if(is.na(byCatDists.dmat[i,k])){
byCatDists.dmat[i,k] = byCatDists.dmat[k,i]
}
}
}
byCatDists.dmat[is.na(byCatDists.dmat)] = 0
# write output matrix
write.table(byCatDists.dmat,file=out.f,sep='\t',row.names=TRUE,col.names=NA)
map = read.csv(map.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
dmat.clmns = data.frame(t(combn(unlist(labels(dmat)[1]),2)),as.numeric(as.dist(dmat)))
dmat = as.matrix(dmat)
dmat.clmns = data.frame(t(combn(unlist(labels(dmat)[1]),2)),as.numeric(as.dist(dmat)))
names(dmat.clmns) = c('x1','x2','dist')
# list x1 and x2 categories in new clmns
cat1 = map[match(dmat.clmns$x1,row.names(map)),cat]
cat2 = map[match(dmat.clmns$x2,row.names(map)),cat]
dmat.clmns = cbind(dmat.clmns,cat1,cat2)
# only take samples in mapping file
dmat.clmns = dmat.clmns[!is.na(dmat.clmns$cat1) & !is.na(dmat.clmns$cat2),]
# retain rows where distances are comparing samples from the same cat
dmat.clmns.reduced = dmat.clmns[dmat.clmns$cat1 != dmat.clmns$cat2,]
# combine cat columns to form comparison categories
# however, need to realize 'cat1__cat2' is equal to 'cat2__cat1'
# make df with every unique combination of cat levels
uniqueLevels = levels(factor(c(as.character(dmat.clmns.reduced$cat1),as.character(dmat.clmns.reduced$cat2))))
categories = data.frame(t(combn(uniqueLevels,2)))
# make a vector with each combination (first,second and second,first) for each combination
categorieslookup = paste(categories[,1],categories[,2])
categorieslookup = c(categorieslookup,paste(categories[,2],categories[,1]))
# make a vector with an index number for each combination of cat levels that associates with lookup vec
catIndex = c(seq.int(1,nrow(categories)),seq.int(1,nrow(categories)))
# now match the category combination (cat1 + cat2) in the dataset to the combination in
#    the lookup vec and pull the category index
joinedCats = paste(dmat.clmns.reduced$cat1,dmat.clmns.reduced$cat2)
distCats = catIndex[match(joinedCats,categorieslookup)]
dmat.clmns.reduced = cbind(dmat.clmns.reduced,distCats)
# get measure of center for each distance category
byCatDists = tapply(dmat.clmns.reduced$dist,INDEX=dmat.clmns.reduced$distCats,FUN=fun)
byCatDists.clms = cbind(as.character(categories[,1]),as.character(categories[,2]),as.vector(byCatDists))
row.names(byCatDists.clms) = NULL
# convert 3 column distances back to matrix format
fun = mean
byCatDists = tapply(dmat.clmns.reduced$dist,INDEX=dmat.clmns.reduced$distCats,FUN=fun)
byCatDists.clms = cbind(as.character(categories[,1]),as.character(categories[,2]),as.vector(byCatDists))
row.names(byCatDists.clms) = NULL
# convert 3 column distances back to matrix format
uNames = as.character(uniqueLevels)
byCatDists.dmat = data.frame(matrix(ncol=length(uNames),nrow=length(uNames)))
names(byCatDists.dmat) = uNames
row.names(byCatDists.dmat) = uNames
for(i in 1:nrow(byCatDists.clms)){
byCatDists.dmat[byCatDists.clms[i,1],byCatDists.clms[i,2]] = as.character(byCatDists.clms[i,3])
}
for(i in 1:nrow(byCatDists.dmat)){
for(k in 1:ncol(byCatDists.dmat)){
if(is.na(byCatDists.dmat[i,k])){
byCatDists.dmat[i,k] = byCatDists.dmat[k,i]
}
}
}
byCatDists.dmat[is.na(byCatDists.dmat)] = 0
# write output matrix
write.table(byCatDists.dmat,file=out.f,sep='\t',row.names=TRUE,col.names=NA)
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/ARISA_dissim_avgByRegionSite.txt'
bd = read.table(file=fp, header=T, sep='\t', row.names=1, check.names=F)
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/regionSite_region_map.csv'
md = read.csv(file=fp, header=T, row.names=1, check.names=F)
# make sure order/samples line up
samplesToUse = intersect(row.names(md),row.names(bd))
bd.use = bd[match(samplesToUse,row.names(bd)),match(samplesToUse,names(bd))]
md.use = md[match(samplesToUse,row.names(md)),]
# do ordinations (NMDS)
# format dm
distMat = as.dist(bd.use)
# Do NMDS
mds = metaMDS(distMat, k=2)
md.use = md[match(samplesToUse,row.names(md)),]
md.use
toPlot = data.frame(mds$points, region = md.use)
ggplot(toPlot, aes(MDS1, MDS2, colour=region)) +
geom_point(alpha=0.8, size=3) +
theme_bw() + xlab('MDS1')
library(ggplot2)
ggplot(toPlot, aes(MDS1, MDS2, colour=region)) +
geom_point(alpha=0.8, size=3) +
#   scale_color_continuous(low='goldenrod',high='darkblue') +
theme_bw() + xlab('MDS1')
data.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data.txt'
dmat.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data.txt'
dmat = read.table(dmat.f,header=TRUE,sep='\t',row.names=1,check.names=FALSE,comment.char="")
map.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/mapping_files/map-all-2010.txt'
cat = "regionSite"
fun = mean
out.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/beta_div/bc_5000_2010data_avgByRegionSite.txt'
map = read.csv(map.f,header=TRUE,row.names=1,check.names=FALSE,comment.char="")
map = read.table(map.f,header=TRUE,sep='\t',row.names=1,check.names=FALSE,comment.char="")
# convert dmat to 3 column format
dmat = as.matrix(dmat)
dmat.clmns = data.frame(t(combn(unlist(labels(dmat)[1]),2)),as.numeric(as.dist(dmat)))
names(dmat.clmns) = c('x1','x2','dist')
# list x1 and x2 categories in new clmns
cat1 = map[match(dmat.clmns$x1,row.names(map)),cat]
cat2 = map[match(dmat.clmns$x2,row.names(map)),cat]
dmat.clmns = cbind(dmat.clmns,cat1,cat2)
# only take samples in mapping file
dmat.clmns = dmat.clmns[!is.na(dmat.clmns$cat1) & !is.na(dmat.clmns$cat2),]
# retain rows where distances are comparing samples from the same cat
dmat.clmns.reduced = dmat.clmns[dmat.clmns$cat1 != dmat.clmns$cat2,]
# combine cat columns to form comparison categories
# however, need to realize 'cat1__cat2' is equal to 'cat2__cat1'
# make df with every unique combination of cat levels
uniqueLevels = levels(factor(c(as.character(dmat.clmns.reduced$cat1),as.character(dmat.clmns.reduced$cat2))))
categories = data.frame(t(combn(uniqueLevels,2)))
# make a vector with each combination (first,second and second,first) for each combination
categorieslookup = paste(categories[,1],categories[,2])
categorieslookup = c(categorieslookup,paste(categories[,2],categories[,1]))
# make a vector with an index number for each combination of cat levels that associates with lookup vec
catIndex = c(seq.int(1,nrow(categories)),seq.int(1,nrow(categories)))
# now match the category combination (cat1 + cat2) in the dataset to the combination in
#    the lookup vec and pull the category index
joinedCats = paste(dmat.clmns.reduced$cat1,dmat.clmns.reduced$cat2)
distCats = catIndex[match(joinedCats,categorieslookup)]
dmat.clmns.reduced = cbind(dmat.clmns.reduced,distCats)
# get measure of center for each distance category
byCatDists = tapply(dmat.clmns.reduced$dist,INDEX=dmat.clmns.reduced$distCats,FUN=fun)
byCatDists.clms = cbind(as.character(categories[,1]),as.character(categories[,2]),as.vector(byCatDists))
row.names(byCatDists.clms) = NULL
# convert 3 column distances back to matrix format
uNames = as.character(uniqueLevels)
byCatDists.dmat = data.frame(matrix(ncol=length(uNames),nrow=length(uNames)))
names(byCatDists.dmat) = uNames
row.names(byCatDists.dmat) = uNames
for(i in 1:nrow(byCatDists.clms)){
byCatDists.dmat[byCatDists.clms[i,1],byCatDists.clms[i,2]] = as.character(byCatDists.clms[i,3])
}
for(i in 1:nrow(byCatDists.dmat)){
for(k in 1:ncol(byCatDists.dmat)){
if(is.na(byCatDists.dmat[i,k])){
byCatDists.dmat[i,k] = byCatDists.dmat[k,i]
}
}
}
byCatDists.dmat[is.na(byCatDists.dmat)] = 0
# write output matrix
write.table(byCatDists.dmat,file=out.f,sep='\t',row.names=TRUE,col.names=NA)
out.f = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data_avgByRegionSite.txt'
write.table(byCatDists.dmat,file=out.f,sep='\t',row.names=TRUE,col.names=NA)
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data_avgByRegionSite.txt'
bd = read.table(file=fp, header=T, sep='\t', row.names=1, check.names=F)
# load in metadata
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/regionSite_region_map.csv'
md = read.csv(file=fp, header=T, row.names=1, check.names=F)
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data_avgByRegionSite.txt'
bd = read.table(file=fp, header=T, sep='\t', row.names=1, check.names=F)
# load in metadata
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/regionSite_region_map.csv'
md = read.csv(file=fp, header=T, row.names=1, check.names=F)
# make sure order/samples line up
samplesToUse = intersect(row.names(md),row.names(bd))
bd.use = bd[match(samplesToUse,row.names(bd)),match(samplesToUse,names(bd))]
md.use = md[match(samplesToUse,row.names(md)),]
# do ordinations (NMDS)
# format dm
distMat = as.dist(bd.use)
# Do NMDS
mds = metaMDS(distMat, k=2)
# extract important data
toPlot = data.frame(mds$points, region = md.use)
# plot(toPlot[,1:2], col=toPlot$pH)
ggplot(toPlot, aes(MDS1, MDS2, colour=region)) +
geom_point(alpha=0.8, size=3) +
#   scale_color_continuous(low='goldenrod',high='darkblue') +
theme_bw() + xlab('MDS1')
fp.NGS = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data_avgByRegionSite.txt'
bd.NGS = read.table(file=fp, header=T, sep='\t', row.names=1, check.names=F)
fp.NGS = '/Users/leffj/Dropbox/NZ-Auckland/streams/clustering_output/beta_div/bc_5000_2010data_avgByRegionSite.txt'
bd.NGS = read.table(file=fp.NGS, header=T, sep='\t', row.names=1, check.names=F)
fp = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/regionSite_region_map.csv'
md = read.csv(file=fp, header=T, row.names=1, check.names=F)
samplesToUse = intersect(row.names(md),row.names(bd.NGS))
bd.NGS.use = bd.NGS[match(samplesToUse,row.names(bd.NGS)),match(samplesToUse,names(bd.NGS))]
md.use = md[match(samplesToUse,row.names(md)),]
fp.ARISA = '/Users/leffj/Dropbox/NZ-Auckland/streams/ARISA_data/ARISA_dissim_avgByRegionSite.txt'
bd.ARISA = read.table(file=fp.ARISA, header=T, sep='\t', row.names=1, check.names=F)
samplesToUse = intersect(row.names(md),row.names(bd.NGS),row.names(bd.ARISA))
samplesToUse = intersect(row.names(bd.ARISA),intersect(row.names(md),row.names(bd.NGS)))
bd.NGS.use = bd.NGS[match(samplesToUse,row.names(bd.NGS)),match(samplesToUse,names(bd.NGS))]
samplesToUse = intersect(row.names(bd.ARISA),intersect(row.names(md),row.names(bd.NGS)))
bd.NGS.use = bd.NGS[match(samplesToUse,row.names(bd.NGS)),match(samplesToUse,names(bd.NGS))]
bd.ARISA.use = bd.ARISA[match(samplesToUse,row.names(bd.ARISA)),match(samplesToUse,names(bd.ARISA))]
md.use = md[match(samplesToUse,row.names(md)),]
md.use
names(md.use)
labels(md.use)
View(bd.ARISA.use)
View(bd.ARISA)
View(bd.NGS)
View(bd.NGS.use)
NGS.dm = as.dist(bd.NGS.use)
ARISA.dm = as.dist(bd.ARISA.use)
plot(ARISA.dm,NGS.dm)
mantel(ARISA.dm,NGS.dm,method='spearman')
